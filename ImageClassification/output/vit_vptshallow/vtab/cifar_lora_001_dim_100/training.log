2024-11-07 10:41:00,947 - training - INFO - Namespace(seed=42, lr=0.001, wd=0.0001, eval='True', dpr=0.1, topN=100, model='vit_base_patch16_224_in21k_vptshallow', model_checkpoint='../checkpoints/B_16.pth', model_type='vit_vptshallow', task='vtab', dataset='cifar100', tuning_mode='vptshallow')
2024-11-07 10:41:00,947 - training - INFO - {'name': 'cifar_lora_001', 'class_num': 100, 'train_aug': False, 'topN': 96, 'labelsmoothing': 0.1, 'batch_size': 64, 'epochs': 100, 'warmup_epochs': 10}
2024-11-07 10:42:31,677 - training - INFO - Namespace(seed=42, lr=0.001, wd=0.0001, eval='True', dpr=0.1, topN=100, model='vit_base_patch16_224_in21k_vptshallow', model_checkpoint='../checkpoints/B_16.pth', model_type='vit_vptshallow', task='vtab', dataset='cifar100', tuning_mode='vptshallow')
2024-11-07 10:42:31,677 - training - INFO - {'name': 'cifar_lora_001', 'class_num': 100, 'train_aug': False, 'topN': 96, 'labelsmoothing': 0.1, 'batch_size': 64, 'epochs': 100, 'warmup_epochs': 10}
2024-11-07 10:42:31,682 - training - INFO - Data transform, train:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2024-11-07 10:42:31,682 - training - INFO - Data transform, test:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2024-11-07 10:49:55,200 - training - INFO - Namespace(seed=42, lr=0.001, wd=0.0001, eval='True', dpr=0.1, topN=100, model='vit_base_patch16_224_in21k_vptshallow', model_checkpoint='../checkpoints/ViT-B_16.npz', model_type='vit_vptshallow', task='vtab', dataset='cifar100', tuning_mode='vptshallow')
2024-11-07 10:49:55,200 - training - INFO - {'name': 'cifar_lora_001', 'class_num': 100, 'train_aug': False, 'topN': 96, 'labelsmoothing': 0.1, 'batch_size': 64, 'epochs': 100, 'warmup_epochs': 10}
2024-11-07 10:49:55,202 - training - INFO - Data transform, train:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2024-11-07 10:49:55,203 - training - INFO - Data transform, test:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2024-11-07 10:50:02,042 - training - INFO - prompt_embeddings
2024-11-07 10:50:02,045 - training - INFO - head.weight
2024-11-07 10:50:02,045 - training - INFO - head.bias
2024-11-07 10:50:02,048 - training - INFO - number of extra params: 153700
2024-11-07 10:50:02,048 - training - INFO - label smoothing
2024-11-07 10:51:33,919 - training - INFO - Namespace(seed=42, lr=0.001, wd=0.0001, eval='True', dpr=0.1, topN=100, model='vit_base_patch16_224_in21k_vptshallow', model_checkpoint='../checkpoints/ViT-B_16.npz', model_type='vit_vptshallow', task='vtab', dataset='cifar100', tuning_mode='vptshallow')
2024-11-07 10:51:33,920 - training - INFO - {'name': 'cifar_lora_001', 'class_num': 100, 'train_aug': False, 'topN': 96, 'labelsmoothing': 0.1, 'batch_size': 12, 'epochs': 100, 'warmup_epochs': 10}
2024-11-07 10:51:33,922 - training - INFO - Data transform, train:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2024-11-07 10:51:33,922 - training - INFO - Data transform, test:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2024-11-07 10:51:39,244 - training - INFO - prompt_embeddings
2024-11-07 10:51:39,246 - training - INFO - head.weight
2024-11-07 10:51:39,246 - training - INFO - head.bias
2024-11-07 10:51:39,248 - training - INFO - number of extra params: 153700
2024-11-07 10:51:39,248 - training - INFO - label smoothing
